Early Detection of Knee Arthritis Using AI: Enhancing Diagnostic Accuracy with Deep Learning
Introduction
Arthritis is among the most common conditions that normally results in chronic pain and loss of mobility in millions of people worldwide; the most susceptible part is knee arthritis. Treatment of arthritis, especially at early stages, requires the diagnosis to be precise (Reference). The X-ray image diagnosis of arthritis can be challenging since the differences among the stages of the disease are not easily marked. There is a need for an automated system to classify knee arthritis X-ray images into five stages: normal, doubtful, mild, moderate, and severe. Doctors can identify conditions faster and more accurately using machine learning, which might translate into better patient care.
It is important to address the limitations of manual diagnoses, which can be slow and prone to human error. Automating this classification process would make the diagnosis more consistent and efficient, particularly in those areas where access to specialized doctors is poor. An AI-based classification system could also help identify patients in need of urgent treatment, making sure that those with severe arthritis get the care they need as quickly as possible. This approach not only expedites the process of diagnosis but also ensures proper treatment for the concerned patients at the right time.
The use of artificial intelligence (AI) in medical imaging, particularly for musculoskeletal conditions like arthritis, has gained significant attention in recent years. Many works also target the implementation of machine learning algorithms, most especially CNNs, for the diagnosis and classification of arthritis from X-ray images. It was demonstrated in Tiulpin et al. 2018 that CNNs have great potential in quantifying the severity of osteoarthritis. The results obtained were close to those from trained radiologists. These results point to certain possibilities of AI improving diagnostic precision and facilitating workflow, possibly reducing human errors regarding the detection and classification of arthritis severity. However, certain challenges to the widespread dissemination of AI for arthritis diagnosis still exist. First, there is an issue with the datasets these models have used for training. Most of the reviewed studies concluded that one needs to move toward more diverse and comprehensive datasets that would allow generalization across a wide range of populations and conditions by AI models. Although deep learning models prove to be very effective, their "black box" nature has raised several related concerns pertaining to interpretability and trust of clinical decision-making. Ongoing research is directed toward improving the interpretability of these models so they will smoothly fit into clinical practice, providing accuracy with explainability in real-world healthcare settings.
The primary goal of the model is to automate the classification of knee arthritis X-ray images into five stages: Normal, Doubtful, Mild, Moderate, and Severe. By doing so, the model can provide doctors with a reliable tool to identify the progression of arthritis with greater consistency and precision. Early detection of arthritis stages is critical to ensuring that patients receive appropriate care at the right time, helping to slow disease progression and improve long-term outcomes. The model aims to address the limitations of manual diagnoses, which can be time-consuming, subjective, and prone to human error.
One of the key objectives of the model is to reduce the diagnostic variability that often exists between different radiologists. Even experienced doctors have differing opinions on the severity of arthritis when reviewing the same X-ray images, particularly in the early stages of the disease where differences are subtle. By creating a consistent, automated classification system, the model can help standardize diagnoses and reduce discrepancies. This consistency is especially valuable in remote or underserved areas, where access to highly trained specialists may be limited. With an AI-based tool, primary care doctors or general practitioners could make more accurate assessments, ensuring that patients with severe arthritis receive timely referrals to specialists.
Another important objective is to help doctors track the progression of arthritis over time. The model’s ability to classify arthritis into distinct stages allows healthcare providers to monitor patients more effectively. For example, if a patient’s condition shifts from Mild to Moderate over several months, doctors can adjust treatment plans accordingly to slow down further deterioration. This stage-wise classification also provides patients with clearer insights into their condition, helping them understand how their disease is progressing and what interventions may be necessary.
In addition to providing accurate classifications, the model seeks to address a critical challenge in AI healthcare solutions: trust and interpretability. Many existing AI models act as "black boxes," delivering results without explanations, which can make doctors hesitant to rely on them. This study emphasizes the importance of making the model’s predictions interpretable, so doctors can understand the reasoning behind each classification. By incorporating explainable AI techniques, the model aims to build trust among healthcare providers, making it more likely to be adopted in clinical practice. The ultimate objective is to create a practical, scalable solution that improves the speed and accuracy of arthritis diagnosis while supporting doctors in providing better patient guidance.
Dataset
The dataset utilized in this study consists of images designated for classifying various stages of knee arthritis. These images are organized into categories representing different severity levels: ‘Normal,’ 'Doubtful,' 'Mild,' 'Moderate,' and 'Severe.' Figure 1 illustrates an example of these different severity levels. The grayscale images, undergo preprocessing steps including resizing and normalization. After preprocessing, each image is resized to a consistent 300x160 pixels. This standardization ensures continuity across the dataset, which is crucial for effective model training.
Figure 1. Images of doubtful, mild, moderate, severe cases of arthritis
The dataset encompasses a substantial number of images, with varying amounts across the categories as shown in Figure 2.  The 'Normal' and 'Doubtful' categories have the highest number of images, with 517 and 477 respectively, while the 'Mild,' 'Moderate,' and 'Severe' categories have fewer, with 232, 221, and 206 images each. The images are split into training and testing subsets to prepare the data for model development. Approximately 80% of the images are allocated for training, while the remaining 20% are reserved for testing. This division allows for thorough model training and provides a means to evaluate the model's performance on new, unseen data.
Figure 2.count distribution of different knee arthritis categories

Methods and Models

CNN(Convolutional Neural Networks)
A CNN is a class of deep learning model visualized to operate on data presented in gridlike structures, for instance, images, videos, and time-series data. The most important reason why CNNs outperform other algorithms in computer vision tasks is that they automatically learn and detect spatial hierarchies of features, ranging from low-level details such as edges to high-level patterns such as objects, without explicit manual feature engineering. The key word here is that by the use of convolution operations, CNNs efficiently preprocess data with local dependencies. This is quite an improvement in contrast with traditional neural networks, where each input pattern is considered independently. Besides, CNNs reflect the hierarchical processing of a visual signal that takes place in the human brain, where neurons of the visual cortex are responsible for recognition of features at different spatial scales. These bio-inspired architectures enhance the generalization capability of the model across diverse visual contexts and tasks. 
CNN architecture generally consists of three major components: convolutional layers, pooling layers, and fully connected layers. Convolutional Layers: In convolutional layers, filters or kernels slide over the input data, capturing features at a specific spatial location. Normally, pooling layers follow convolutional layers to down-sample data in order to decrease computational load while making the network invariant or robust to spatial transformations like translation and rotation. Fully connected layers serve to map the learned features to what is usually the ultimate output, typically a classification decision. Finally, an activation function, such as ReLU, follows each convolutional layer for the purpose of introducing nonlinearities into the network to enrich its capabilities of capturing complicated patterns. Training the CNN involves updating of weights through backpropagation and optimization algorithms such as stochastic gradient descent, through iteratively minimizing the loss function over many iterations of data.
CNNs have revolutionized several areas other than computer vision, including medical imaging, speech recognition, and natural language processing. In medical applications, CNNs are employed in the analysis of radiological images to assist in anomaly detection, such as tumors or bone fractures, with a very high degree of accuracy. In this line, CNNs are also crucial in object detection in real time for autonomous driving systems to find pedestrians, traffic signs, and other vehicles. More recently, innovation in CNN architectures such as AlexNet, VGG, ResNet, and Inception has shown impressive performance improvements, establishing new benchmarks on accuracy in image classification and object detection tasks. This has helped increase not only the functionalities but also the application areas for the deep learning models.
InceptionV3
InceptionV3 is a very advanced, deep convolutional neural network that tries to achieve an optimal balance between computational efficiency and image classification accuracy. It was developed as part of the Google Inception family, introducing the notion of "Inception modules," which perform convolutions at multiple scales simultaneously. Using parallel convolutions with different filter sizes (1x1, 3x3, and 5x5) and aggregating the outputs, InceptionV3 extracts both fine-grained and large-scale features in images, making it particularly effective for complex classification tasks.
In this work, we employed a pre-trained InceptionV3 model, fine-tuned for the classification of knee arthritis stages. Pre-trained layers of the model were trained on the ImageNet dataset and were initially frozen in order to leverage their ability to detect basic visual patterns. Then, a custom classification head was added consisting of a GlobalAveragePooling2D layer, a dense layer with 512 neurons and ReLU activation, a dropout layer to mitigate overfitting, and a softmax output layer to classify the five arthritis stages. After training the added layers, fine-tuning was done by unfreezing the last few layers of the InceptionV3 base model and training these with a reduced learning rate, adapting the model to the specifics of the dataset.
EfficientNet
EfficientNet is a state-of-the-art CNN architecture that achieves remarkable performance with minimal computational cost. Unlike traditional CNNs, which often scale up the depth or width of the network arbitrarily, EfficientNet uses a principled compound scaling method. This approach scales the depth, width, and resolution of the network systematically, optimizing the trade-offs between accuracy and efficiency.
For this study, EfficientNetB0, the base variant of the EfficientNet family, was fine-tuned for arthritis classification. The pre-trained model was initially frozen to retain the generic visual features learned from the ImageNet dataset. A custom classification head was added, consisting of a GlobalAveragePooling2D layer, a dense layer with 512 neurons using ReLU activation, a dropout layer to prevent overfitting, and a softmax layer for multi-class classification. The model was then fine-tuned by unfreezing the last few layers and training them with a lower learning rate to adapt the pre-trained weights to the arthritis dataset.
EfficientNet’s compound scaling and squeeze-and-excitation modules enhanced the model’s ability to focus on the most relevant features in the X-ray images while reducing noise. This efficiency made EfficientNet particularly suitable for medical imaging tasks, where computational resources may be limited. By combining EfficientNet’s scalability with data augmentation and techniques like the ReduceLROnPlateau callback, the model achieved a balanced performance across all arthritis stages, even for the underrepresented classes.
DenseNet
DenseNet is a modern CNN architecture that maximizes the information flow between layers by connecting each layer to every other subsequent layer in a feed-forward fashion. Such dense connections help reduce the vanishing gradient problem, diminish redundancy, and improve feature reuse, making DenseNet highly effective and efficient for medical imaging tasks.
In this study, the authors used a 121-layer model of DenseNet and fine-tuned it for the classification of arthritis. The pre-trained weights from the model were frozen, which had been trained on ImageNet. A custom classification head was added, which consisted of a GlobalAveragePooling2D layer, a dense layer of 512 neurons using ReLU activation, a dropout layer to handle overfitting, and finally a softmax layer for the classification of five stages of arthritis. Fine-tuning involved unfreezing the last few dense blocks and retraining them with a reduced learning rate.
Densely connected layers in DenseNet allowed the model to grab features from shallow to deep, making it very proficient in describing minute differences among stages in arthritis. Data augmentation techniques, along with the Adam optimizer, were also employed for better enhancement of the model's performance. This efficient use of parameters decreases the chances of overfitting while maintaining the high classification accuracy in DenseNet; hence, it was selected as a robust model for this work.

Evaluation Metrics
A confusion matrix is a simple evaluation device that helps in comparing predicted labels with actual labels. This confusion matrix tabulates the actual classes on the rows and predicted classes on the columns to give a complete breakup of model performance across categories. It shows four key outcomes: true positives, indicating correct predictions for positive instances; true negatives, indicating correct predictions for negative instances; false positives, meaning incorrectly predicted positive instances; and false negatives, which are incorrectly predicted negative instances. That would allow for nuancing in the model's mistakes to better identify the specific weaknesses, such as over-predicting some classes or under-predicting others. In medical diagnosis, for example, a high rate of false negatives could be critical because it would mean that your model is missing the disease cases.
While the confusion matrix gives some insight into the raw results, the classification report goes into more detail for quantitative analysis of the model's performance with metrics such as precision, recall, F1-score, and support. Precision, on the other hand, is defined as the ratio of positive predictions actually true to all positive predictions; this is very useful in applications where the cost of false positives is prohibitive, such as in spam detection. Recall or sensitivity is the measure that informs about how many relevant instances in the dataset the model is able to detect; therefore, it is a very valuable metric when there are cases of false negatives that one would not want to see. The F1-score expresses precision and recall in a single metric by calculating their harmonic mean. Therefore, this gives a good balance between the two when making an evaluation of the accuracy of a model, especially in those cases where precision and recall are at odds. It is the support metric that will provide essentially the number of actual instances per class, thus helping in the evaluation of model performance within the context of a class distribution, making sure-for example-good performance is not only for the majority classes but also for the minority ones.

Transfer Learning Model Modifications
In this study, several transfer learning models were fine-tuned to classify knee arthritis stages with greater accuracy and efficiency. Transfer learning involves leveraging pre-trained models that have already learned general features from large datasets, and adapting them to the specific task at hand. By fine-tuning these models, we aim to reduce training time, improve performance on limited medical datasets, and enhance the generalization capability of the model. Three state-of-the-art CNN architectures were selected for this study: EfficientNetB0, InceptionV3, and DenseNet121. Each model underwent specific modifications to optimize its performance on the knee arthritis dataset. The base layers of these models were initially frozen to retain the pre-trained knowledge of general image features, such as edges and textures. Subsequently, new layers were added on top to adapt the models for the classification of arthritis stages. After training the new layers, fine-tuning was performed by unfreezing select layers from the base models to further improve performance by allowing the models to learn more task-specific features from the dataset.
Layer Modifications
For each model, the number of layers unfrozen varied depending on the architecture’s depth and complexity. In the case of EfficientNetB0, the final 20 layers of the base model were unfrozen to allow the network to learn task-specific features from the arthritis images. Similarly, for InceptionV3, the last 50 layers were unfrozen, while for DenseNet121, the final dense blocks were unfrozen to refine the model’s performance on the target dataset. After unfreezing these layers, we added custom classification heads tailored to the arthritis classification task. The new layers included a GlobalAveragePooling2D layer to reduce the dimensionality of the feature maps and retain the most critical features. This was followed by a fully connected Dense layer with 512 neurons and ReLU activation, which introduced non-linearity to enhance the model's learning capacity. A Dropout layer with a dropout rate of 0.5 was added to mitigate overfitting by randomly deactivating 50% of neurons during each training iteration. Finally, a Dense output layer with five neurons and a softmax activation function was added to classify the images into the five categories of arthritis severity: Normal, Doubtful, Mild, Moderate, and Severe.
Compilation and Optimization
Each modified model was compiled using the Adam optimizer, which is widely used for its adaptive learning rate and efficient handling of sparse gradients. The loss function selected was sparse categorical cross entropy, appropriate for multi-class classification problems where the target labels are integers. The model's performance was evaluated using accuracy as the primary metric, ensuring the model's ability to correctly classify images into the correct arthritis stages. To further optimize training, a learning rate scheduler (ReduceLROnPlateau) was employed. This callback function monitored the validation loss during training and reduced the learning rate by a factor of 0.5 when the validation loss plateaued for five consecutive epochs. This dynamic adjustment of the learning rate allowed the model to converge more effectively by taking larger steps during initial training and smaller steps as it approached the optimal solution.
Training Process
The training process consisted of two stages: initial training with frozen base layers and subsequent fine-tuning with unfrozen layers. During the initial training phase, only the newly added layers were trained, allowing the model to adapt the high-level features learned from the base model to the arthritis dataset. Once the new layers reached a satisfactory level of performance, the fine-tuning phase began. In the fine-tuning phase, select layers from the pre-trained base models were unfrozen, and the entire model was trained with a reduced learning rate. This step allowed the models to adjust their pre-trained features to better capture the specific patterns in knee arthritis X-ray images. The models were trained for 100 epochs, with early stopping criteria to prevent overfitting. Data augmentation techniques were applied during training to improve the model's robustness by introducing variations in the input images, such as rotations, zooms, and flips. The combination of pre-trained knowledge, customized classification heads, and fine-tuning led to an optimized performance of all three models, achieving a balanced accuracy across the different arthritis stages, even for underrepresented categories like Mild and Severe.
Results and Discussion 
Base CNN Model:
Figure X - Testing data classification report.
The classification report presented in Figure X provides a detailed evaluation of the Base CNN model’s performance across five categories of knee arthritis severity: Normal, Doubtful, Mild, Moderate, and Severe. The primary metrics analyzed in the report include Precision, Recall, F1-score, and Support, which collectively offer insights into the model's capability to classify X-ray images accurately.
The model achieved an overall accuracy of 64%, indicating that the model correctly classified 64% of the test images across all categories. The macro average F1-score was 0.60, which shows that the model’s performance is balanced across all categories, irrespective of the number of samples in each class. The weighted average F1-score, which accounts for class imbalances, was slightly higher at 0.62, indicating that the model performs better for the more populated categories.
Among the five classes, the model shows the highest performance for the Moderate category, achieving an F1-score of 0.71. This indicates that the model effectively identifies X-ray images with moderate arthritis symptoms. The Severe category also demonstrates strong performance, with a recall of 0.83, meaning that the model correctly identified 83% of the actual severe cases in the test set. The model’s high recall for severe cases is particularly important in medical settings, as it ensures that patients with advanced arthritis are accurately flagged for urgent medical attention.
On the other hand, the model struggles significantly with the Mild category, achieving a low F1-score of 0.26. The recall for Mild cases is 0.20, indicating that the model fails to identify 80% of actual mild cases. This is concerning, as early detection of arthritis is critical to slowing disease progression and improving long-term outcomes. The poor performance in this category suggests that the model finds it challenging to distinguish subtle differences between early-stage arthritis and other stages, which highlights the need for further model refinement.
The Normal and Doubtful categories show moderate performance, with F1-scores of 0.70 and 0.66, respectively. The model's recall for Normal cases is 0.72, indicating that the majority of healthy knee X-rays are correctly identified. However, some confusion exists between Normal and Doubtful cases, likely due to overlapping visual features in the X-ray images.

  






