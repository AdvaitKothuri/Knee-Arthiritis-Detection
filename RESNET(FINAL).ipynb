{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "149feef8-01cb-4bc1-b795-dbe8d79658c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07cb13c-be9f-438b-b5dc-ef95b2fcd96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fce7624-8a64-4292-b162-86c46039c82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1320 validated image filenames belonging to 5 classes.\n",
      "Found 330 validated image filenames belonging to 5 classes.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "2024-12-12 21:31:42.748126: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:37: Filling up shuffle buffer (this may take a while): 3 of 8\n",
      "2024-12-12 21:31:53.218547: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:37: Filling up shuffle buffer (this may take a while): 6 of 8\n",
      "2024-12-12 21:32:00.696782: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m712s\u001b[0m 4s/step - accuracy: 0.2787 - loss: 1.7780 - val_accuracy: 0.3140 - val_loss: 1.5469 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 1.5207 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 672ms/step - accuracy: 0.3139 - loss: 1.6038 - val_accuracy: 0.2927 - val_loss: 1.5368 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 1.5789 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 697ms/step - accuracy: 0.2911 - loss: 1.6109 - val_accuracy: 0.2866 - val_loss: 1.5452 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.9773 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 689ms/step - accuracy: 0.3253 - loss: 1.5496 - val_accuracy: 0.3140 - val_loss: 1.5286 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 1.6420 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 693ms/step - accuracy: 0.2895 - loss: 1.5808 - val_accuracy: 0.2957 - val_loss: 1.5243 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 2.0711 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553ms/step - accuracy: 0.3159 - loss: 1.5464\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 689ms/step - accuracy: 0.3158 - loss: 1.5464 - val_accuracy: 0.3110 - val_loss: 1.5274 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5000 - val_loss: 1.5429 - learning_rate: 3.0000e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 689ms/step - accuracy: 0.3354 - loss: 1.5374 - val_accuracy: 0.3262 - val_loss: 1.5197 - learning_rate: 3.0000e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 2.0468 - learning_rate: 3.0000e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 692ms/step - accuracy: 0.3049 - loss: 1.5527 - val_accuracy: 0.3140 - val_loss: 1.5184 - learning_rate: 3.0000e-05\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 2.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 21:56:40.276020: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1910s\u001b[0m 12s/step - accuracy: 0.2758 - loss: 1.5430 - val_accuracy: 0.3140 - val_loss: 1.5204 - learning_rate: 9.0000e-06\n",
      "Epoch 18/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 1.6542 - learning_rate: 9.0000e-06\n",
      "Epoch 19/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 691ms/step - accuracy: 0.2790 - loss: 1.5531 - val_accuracy: 0.3140 - val_loss: 1.5186 - learning_rate: 9.0000e-06\n",
      "Epoch 20/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 1.9603 - learning_rate: 9.0000e-06\n",
      "Epoch 21/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560ms/step - accuracy: 0.3252 - loss: 1.5319\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 2.6999998226528985e-06.\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 699ms/step - accuracy: 0.3252 - loss: 1.5319 - val_accuracy: 0.3140 - val_loss: 1.5203 - learning_rate: 9.0000e-06\n",
      "Epoch 22/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 1.6720 - learning_rate: 2.7000e-06\n",
      "Epoch 23/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 736ms/step - accuracy: 0.2869 - loss: 1.5432 - val_accuracy: 0.3110 - val_loss: 1.5203 - learning_rate: 2.7000e-06\n",
      "Epoch 24/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5000 - val_loss: 1.6353 - learning_rate: 2.7000e-06\n",
      "Epoch 25/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 778ms/step - accuracy: 0.3418 - loss: 1.5119 - val_accuracy: 0.3140 - val_loss: 1.5182 - learning_rate: 2.7000e-06\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 1.9902 - learning_rate: 2.7000e-06\n",
      "Epoch 27/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 1s/step - accuracy: 0.3251 - loss: 1.5321 - val_accuracy: 0.3140 - val_loss: 1.5226 - learning_rate: 1.0000e-06\n",
      "Epoch 28/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 1.2610 - learning_rate: 1.0000e-06\n",
      "Epoch 29/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 1s/step - accuracy: 0.2967 - loss: 1.5423 - val_accuracy: 0.3110 - val_loss: 1.5206 - learning_rate: 1.0000e-06\n",
      "Epoch 30/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5000 - val_loss: 1.5838 - learning_rate: 1.0000e-06\n",
      "Epoch 31/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 1s/step - accuracy: 0.3063 - loss: 1.5413 - val_accuracy: 0.3140 - val_loss: 1.5201 - learning_rate: 1.0000e-06\n",
      "Epoch 32/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 1.6628 - learning_rate: 1.0000e-06\n",
      "Epoch 33/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 1s/step - accuracy: 0.3418 - loss: 1.5220 - val_accuracy: 0.3140 - val_loss: 1.5206 - learning_rate: 1.0000e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 1.5713 - learning_rate: 1.0000e-06\n",
      "Epoch 35/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 1s/step - accuracy: 0.3174 - loss: 1.5339 - val_accuracy: 0.3140 - val_loss: 1.5179 - learning_rate: 1.0000e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 2.0262 - learning_rate: 1.0000e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 1s/step - accuracy: 0.3076 - loss: 1.5324 - val_accuracy: 0.3110 - val_loss: 1.5203 - learning_rate: 1.0000e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5000 - val_loss: 1.6297 - learning_rate: 1.0000e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 1s/step - accuracy: 0.3158 - loss: 1.5214 - val_accuracy: 0.3110 - val_loss: 1.5206 - learning_rate: 1.0000e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5000 - val_loss: 1.5725 - learning_rate: 1.0000e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 783ms/step - accuracy: 0.3195 - loss: 1.5427 - val_accuracy: 0.3140 - val_loss: 1.5201 - learning_rate: 1.0000e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 1.6548 - learning_rate: 1.0000e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 698ms/step - accuracy: 0.2913 - loss: 1.5299 - val_accuracy: 0.3140 - val_loss: 1.5204 - learning_rate: 1.0000e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 1.5950 - learning_rate: 1.0000e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 697ms/step - accuracy: 0.3020 - loss: 1.5376 - val_accuracy: 0.3140 - val_loss: 1.5202 - learning_rate: 1.0000e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 1.6397 - learning_rate: 1.0000e-06\n",
      "Epoch 47/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 726ms/step - accuracy: 0.3074 - loss: 1.5476 - val_accuracy: 0.3110 - val_loss: 1.5203 - learning_rate: 1.0000e-06\n",
      "Epoch 48/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5000 - val_loss: 1.6135 - learning_rate: 1.0000e-06\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 23:11:25.732124: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36567s\u001b[0m 223s/step - accuracy: 0.3073 - loss: 1.5368 - val_accuracy: 0.3140 - val_loss: 1.5182 - learning_rate: 1.0000e-06\n",
      "Epoch 50/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 1.9501 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to your data directory\n",
    "data_dir = '/Users/advait/Desktop/Knee_Arthiritis_AI/data'\n",
    "class_names = [\"0Normal\", \"1Doubtful\", \"2Mild\", \"3Moderate\", \"4Severe\"]\n",
    "\n",
    "# Initialize lists to hold file paths and labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Load file paths and labels\n",
    "for idx, class_name in enumerate(class_names):\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    for file_name in os.listdir(class_dir):\n",
    "        if file_name.endswith(\".png\"):\n",
    "            file_paths.append(os.path.join(class_dir, file_name))\n",
    "            labels.append(idx)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "file_paths = np.array(file_paths)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform stratified split\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    file_paths, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Convert numeric labels to string class names\n",
    "train_labels = [class_names[label] for label in train_labels]\n",
    "val_labels = [class_names[label] for label in val_labels]\n",
    "\n",
    "# Data augmentation for the training set\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    rescale=1.0 / 255.0\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "# Create DataFrames for train and validation data\n",
    "train_df = pd.DataFrame({'filename': train_paths, 'class': train_labels})\n",
    "val_df = pd.DataFrame({'filename': val_paths, 'class': val_labels})\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=8,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=8,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Load ResNet50 with pre-trained weights\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze all layers initially\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build the top model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5, min_lr=1e-6, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint('best_resnet_model.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "# Calculate steps per epoch based on generator batch size\n",
    "steps_per_epoch = len(train_paths) // train_generator.batch_size\n",
    "validation_steps = len(val_paths) // validation_generator.batch_size\n",
    "\n",
    "# Train model without EarlyStopping\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[reduce_lr, model_checkpoint],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1bbfa-c612-461c-84c7-de371840d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b155c75-2a77-465e-b31b-7716e7912447",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m y_true_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_true_test)\n\u001b[1;32m     14\u001b[0m y_pred_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_pred_test)\n\u001b[0;32m---> 16\u001b[0m cm_test \u001b[38;5;241m=\u001b[39m confusion_matrix(y_true_test, y_pred_test)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Get true labels from the validation generator\u001b[39;00m\n\u001b[1;32m     18\u001b[0m y_true_train \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# Get true labels from the validation generator\n",
    "y_true_test = []\n",
    "y_pred_test = []\n",
    "\n",
    "batch_size = 8\n",
    "# Make predictions and collect labels\n",
    "for i in range(len(val_paths) // batch_size + 1):  # Process in batches\n",
    "    x_batch, y_batch = next(validation_generator)\n",
    "    y_true_test.extend(np.argmax(y_batch, axis=1))\n",
    "    y_pred_batch = model.predict_on_batch(x_batch)\n",
    "    y_pred_test.extend(np.argmax(y_pred_batch, axis=1))\n",
    "\n",
    "y_true_test = np.array(y_true_test)\n",
    "y_pred_test = np.array(y_pred_test)\n",
    "\n",
    "cm_test = confusion_matrix(y_true_test, y_pred_test)\n",
    "# Get true labels from the validation generator\n",
    "y_true_train = []\n",
    "y_pred_train = []\n",
    "\n",
    "# Make predictions and collect labels\n",
    "for i in range(len(train_paths) // batch_size + 1):  # Process in batches\n",
    "    x_batch, y_batch = next(train_generator)\n",
    "    y_true_train.extend(np.argmax(y_batch, axis=1))\n",
    "    y_pred_batch = model.predict_on_batch(x_batch)\n",
    "    y_pred_train.extend(np.argmax(y_pred_batch, axis=1))\n",
    "\n",
    "y_true_train = np.array(y_true_train)\n",
    "y_pred_train = np.array(y_pred_train)\n",
    "\n",
    "cm_train = confusion_matrix(y_true_train, y_pred_train)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm_train, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Train Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Test Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19da430-ce5c-4e18-ae2e-e1708a65ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report_train = classification_report(y_true_train, y_pred_train, target_names= class_names)\n",
    "print(classification_report_train)\n",
    "\n",
    "classification_report_test = classification_report(y_true_test, y_pred_test, target_names= class_names)\n",
    "print(classification_report_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057527dd-aafc-4f76-b3dc-a671bb4f9cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16218502-4e4d-4ca1-aea7-b2d6babffa29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
